{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e751ac6f-39a7-4cf3-ae70-0bb23e70d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1519126995.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize_tanggal_transaksi(input_xlsx_path: str, output_xlsx_path: str) -> None:\n",
    "    df = pd.read_excel(input_xlsx_path, dtype=str)\n",
    "\n",
    "    bulan = {\n",
    "        'februari':'February','feb':'februari',\n",
    "        'maret':'March','mar':'March',\n",
    "        'april':'April','apr':'April',\n",
    "        'mei':'May','mai':'May',\n",
    "        'juni':'June','jun':'June',\n",
    "        'juli':'July','jul':'July',\n",
    "        'agustus':'August','agu':'August','aug':'August',\n",
    "        'september':'September','sep':'September',\n",
    "        'oktober':'October','okt':'October','oct':'October',\n",
    "        'november':'November','nov':'November',\n",
    "        'desember':'December','des':'December','dec':'December'\n",
    "    }\n",
    "\n",
    "    def fix_date(x):\n",
    "        if pd.isna(x): return x\n",
    "        s = str(x).replace(\",\", \"\").replace(\"'\", \"\").strip()\n",
    "        s = \" \".join([bulan.get(w.lower(), w) for w in s.split()])\n",
    "        if s[:4].isdigit() and len(s.split())==3:\n",
    "            y,d,m = s.split()\n",
    "            s = f\"{d} {m} {y}\"\n",
    "        for dfmt in (True, False):\n",
    "            dt = pd.to_datetime(s, errors='coerce', dayfirst=dfmt)\n",
    "            if pd.notna(dt):\n",
    "                return dt.strftime(\"%d-%m-%Y\")\n",
    "        return x\n",
    "\n",
    "    for c in df.columns:\n",
    "        sample = df[c].dropna().astype(str).head(10)\n",
    "        if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
    "            df[c] = df[c].apply(fix_date)\n",
    "\n",
    "    df.to_csv(output_xlsx_path, index=False)\n",
    "\n",
    "normalize_tanggal_transaksi(\"penjualan_dqmart_01-beta.xlsx\",\"penjualan_dqmart_01-beta_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a58003b0-b349-4e47-b1ab-7141663d3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File berhasil dinormalisasi dan disimpan ke: penjualan_dqmart_01-beta_normalized.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:34: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/414807492.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def normalize_tanggal_transaksi(input_xlsx_path: str, output_csv_path: str) -> None:\n",
    "    # Baca file Excel\n",
    "    df = pd.read_excel(input_xlsx_path, dtype=str)\n",
    "\n",
    "    # Peta bulan Indonesia ke Inggris\n",
    "    bulan_map = {\n",
    "        'januari': 'January', 'jan': 'January',\n",
    "        'februari': 'February', 'feb': 'February',\n",
    "        'maret': 'March', 'mar': 'March',\n",
    "        'april': 'April', 'apr': 'April',\n",
    "        'mei': 'May', 'mei.': 'May',\n",
    "        'juni': 'June', 'jun': 'June',\n",
    "        'juli': 'July', 'jul': 'July',\n",
    "        'agustus': 'August', 'agu': 'August', 'aug': 'August',\n",
    "        'september': 'September', 'sep': 'September',\n",
    "        'oktober': 'October', 'okt': 'October', 'oct': 'October',\n",
    "        'november': 'November', 'nov': 'November',\n",
    "        'desember': 'December', 'des': 'December', 'dec': 'December'\n",
    "    }\n",
    "\n",
    "    def parse_date(s):\n",
    "        if pd.isna(s):\n",
    "            return s\n",
    "        s = str(s).strip()\n",
    "        s = re.sub(r\"[,'’‘]\", \" \", s)\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        s = \" \".join([bulan_map.get(w.lower(), w) for w in s.split()])\n",
    "\n",
    "        # Coba parse otomatis\n",
    "        for dayfirst in (True, False):\n",
    "            dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, infer_datetime_format=True)\n",
    "            if pd.notna(dt):\n",
    "                return dt.strftime(\"%d-%m-%Y\")\n",
    "        return s  # kembalikan jika tidak bisa diparse\n",
    "\n",
    "    # Deteksi kolom tanggal otomatis berdasarkan sample\n",
    "    for col in df.columns:\n",
    "        sample = df[col].dropna().astype(str).head(10)\n",
    "        detect = pd.to_datetime(sample, errors='coerce', dayfirst=True, infer_datetime_format=True)\n",
    "        if detect.notna().sum() >= 3:\n",
    "            df[col] = df[col].apply(parse_date)\n",
    "\n",
    "    # Simpan hasil\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"✅ File berhasil dinormalisasi dan disimpan ke: {output_csv_path}\")\n",
    "\n",
    "# Jalankan fungsi\n",
    "normalize_tanggal_transaksi(\n",
    "    \"penjualan_dqmart_01-beta.xlsx\",\n",
    "    \"penjualan_dqmart_01-beta_normalized.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c06cfe-aad3-4e04-a4aa-cdd0482e455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Standarisasi tanggal selesai. File hasil: penjualan_dqmart_01_normalized.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:50: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, infer_datetime_format=True)\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
      "/tmp/ipykernel_25452/1659880801.py:61: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Fungsi utama untuk menstandarkan penulisan tanggal pada file Excel transaksi\n",
    "def normalize_tanggal_transaksi(input_xlsx_path: str, output_xlsx_path: str) -> None:\n",
    "    # Baca file Excel sesuai instruksi (sheet: transaksi)\n",
    "    df = pd.read_excel(input_xlsx_path, sheet_name='transaksi', dtype=str)\n",
    "\n",
    "    # Mapping nama bulan dalam Bahasa Indonesia ke Bahasa Inggris\n",
    "    # supaya bisa dikenali oleh pandas.to_datetime()\n",
    "    bulan_map = {\n",
    "        'januari': 'January', 'jan': 'January',\n",
    "        'februari': 'February', 'feb': 'February',\n",
    "        'maret': 'March', 'mar': 'March',\n",
    "        'april': 'April', 'apr': 'April',\n",
    "        'mei': 'May', 'mei.': 'May',\n",
    "        'juni': 'June', 'jun': 'June',\n",
    "        'juli': 'July', 'jul': 'July',\n",
    "        'agustus': 'August', 'agu': 'August', 'aug': 'August',\n",
    "        'september': 'September', 'sep': 'September',\n",
    "        'oktober': 'October', 'okt': 'October', 'oct': 'October',\n",
    "        'november': 'November', 'nov': 'November',\n",
    "        'desember': 'December', 'des': 'December', 'dec': 'December'\n",
    "    }\n",
    "\n",
    "    # Fungsi kecil untuk membersihkan dan menormalkan format tanggal\n",
    "    def parse_date(val):\n",
    "        if pd.isna(val):\n",
    "            return val\n",
    "        s = str(val).strip()\n",
    "\n",
    "        # Hapus karakter yang sering bikin parsing gagal\n",
    "        s = re.sub(r\"[,’‘’]\", \" \", s)\n",
    "        s = s.replace(\",\", \" \")\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "        # Ubah nama bulan lokal (Indonesia) ke format Inggris\n",
    "        s = \" \".join([bulan_map.get(w.lower(), w) for w in s.split()])\n",
    "\n",
    "        # Ubah tahun dua digit seperti '24 menjadi 2024\n",
    "        s = re.sub(r\"'\\s*(\\d{2})(?!\\d)\", r\"20\\1\", s)\n",
    "\n",
    "        # Tangani pola seperti \"2024, 6 Nov\" agar jadi \"6 Nov 2024\"\n",
    "        match = re.match(r\"^(\\d{4})\\s*,\\s*(\\d{1,2})\\s+([A-Za-z]+)\", s)\n",
    "        if match:\n",
    "            s = f\"{match.group(2)} {match.group(3)} {match.group(1)}\"\n",
    "\n",
    "        # Coba parse dengan dua kemungkinan format (day first dan month first)\n",
    "        for dayfirst in (True, False):\n",
    "            dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, infer_datetime_format=True)\n",
    "            if pd.notna(dt):\n",
    "                return dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        # Kalau gagal diparse, kembalikan nilai aslinya\n",
    "        return val\n",
    "\n",
    "    # Deteksi otomatis kolom yang isinya tanggal\n",
    "    # (dicek berdasarkan 10 sampel pertama di tiap kolom)\n",
    "    for col in df.columns:\n",
    "        sample = df[col].dropna().astype(str).head(10)\n",
    "        if pd.to_datetime(sample, errors='coerce', dayfirst=True).notna().sum() >= 3:\n",
    "            df[col] = df[col].apply(parse_date)\n",
    "\n",
    "    # Simpan hasil ke Excel baru dengan struktur kolom tetap sama\n",
    "    df.to_excel(output_xlsx_path, index=False, sheet_name='transaksi')\n",
    "\n",
    "    print(f\"✅ Standarisasi tanggal selesai. File hasil: {output_xlsx_path}\")\n",
    "\n",
    "\n",
    "# Eksekusi utama\n",
    "if __name__ == \"__main__\":\n",
    "    # File input dan output sesuai instruksi hackathon\n",
    "    normalize_tanggal_transaksi(\n",
    "        \"penjualan_dqmart_01-beta.xlsx\",\n",
    "        \"penjualan_dqmart_01_normalized.xlsx\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23690959-5a9e-4d09-82e3-7290edf6df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize_tanggal_transaksi(input_xlsx_path: str, output_xlsx_path: str) -> None:\n",
    "    # Baca file Excel\n",
    "    df = pd.read_excel(input_xlsx_path, sheet_name='transaksi', dtype=str)\n",
    "\n",
    "    # Pemetaan bulan Indonesia dan Inggris\n",
    "    bulan = {\n",
    "        'januari': 'January', 'jan': 'January',\n",
    "        'februari': 'February', 'feb': 'February',\n",
    "        'maret': 'March', 'mar': 'March',\n",
    "        'april': 'April', 'apr': 'April',\n",
    "        'mei': 'May', 'may': 'May',\n",
    "        'juni': 'June', 'jun': 'June',\n",
    "        'juli': 'July', 'jul': 'July',\n",
    "        'agustus': 'August', 'agu': 'August', 'aug': 'August',\n",
    "        'september': 'September', 'sep': 'September',\n",
    "        'oktober': 'October', 'okt': 'October', 'oct': 'October',\n",
    "        'november': 'November', 'nov': 'November',\n",
    "        'desember': 'December', 'des': 'December', 'dec': 'December'\n",
    "    }\n",
    "\n",
    "    def fix_date(x):\n",
    "        if pd.isna(x):\n",
    "            return x\n",
    "\n",
    "        s = str(x).strip()\n",
    "        # Bersihkan tanda baca dan kutipan\n",
    "        for ch in [\",\", \".\", \"'\", \"‘\", \"’\", \"–\", \"-\", \"/\", \"\\\\\"]:\n",
    "            s = s.replace(ch, \" \")\n",
    "        s = \" \".join(s.split())\n",
    "\n",
    "        # Ubah nama bulan ke Inggris\n",
    "        s = \" \".join([bulan.get(w.lower(), w) for w in s.split()])\n",
    "\n",
    "        # Tangani format \"YYYY DD MMM\" atau \"YYYY, DD MMM\"\n",
    "        parts = s.split()\n",
    "        if len(parts) == 3 and parts[0].isdigit() and len(parts[0]) == 4:\n",
    "            y, d, m = parts\n",
    "            s = f\"{d} {m} {y}\"\n",
    "\n",
    "        # Tangani format tahun dua digit misal '24\n",
    "        s = s.replace(\"‘\", \"\").replace(\"’\", \"\").strip()\n",
    "        s = s.replace(\"'\", \"\")\n",
    "\n",
    "        # Coba parsing berbagai kemungkinan format\n",
    "        for dayfirst in (True, False):\n",
    "            dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, infer_datetime_format=True)\n",
    "            if pd.notna(dt):\n",
    "                return dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        # Jika gagal, coba paksa perbaikan dengan urutan lain\n",
    "        try:\n",
    "            dt = pd.to_datetime(s, format=\"%Y %m %d\", errors='coerce')\n",
    "            if pd.notna(dt):\n",
    "                return dt.strftime(\"%d-%m-%Y\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Jika tetap gagal, kembalikan nilai asli agar tidak hilang\n",
    "        return x\n",
    "\n",
    "    # Cari kolom yang mengandung tanggal\n",
    "    for col in df.columns:\n",
    "        sample = df[col].dropna().astype(str).head(20)\n",
    "        if sample.apply(lambda x: pd.to_datetime(x, errors='coerce')).notna().sum() >= 3:\n",
    "            df[col] = df[col].apply(fix_date)\n",
    "\n",
    "    # Simpan hasil ke file output dengan format sama\n",
    "    df.to_excel(output_xlsx_path, index=False, sheet_name='transaksi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "527287f8-ab6e-4ace-a72c-7134d3bdc96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevinpjt/env/lib/python3.10/site-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "\n",
    "def run_analysis(input_xlsx_path: str, output_xlsx_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Fungsi utama yang menjalankan seluruh proses analisis pola pembelian.\n",
    "    Fungsi ini membaca data transaksi dari Excel, melakukan analisis dengan algoritma Apriori,\n",
    "    membentuk aturan asosiasi (association rules), dan menyimpan hasil akhirnya\n",
    "    dalam file Excel bernama 'product_packaging.xlsx' sesuai ketentuan soal.\n",
    "    \"\"\"\n",
    "\n",
    "    # =====================================================================\n",
    "    # 1. Membaca data transaksi dari sheet \"Transaksi\"\n",
    "    # =====================================================================\n",
    "    # Kita mulai dengan membuka file Excel yang berisi data transaksi.\n",
    "    # Soal menyebutkan bahwa file memiliki kolom: Kode Transaksi, Nama Produk, dan Jumlah.\n",
    "    # Kolom \"Jumlah\" tidak digunakan dalam analisis, jadi akan diabaikan.\n",
    "    # =====================================================================\n",
    "    df = pd.read_excel(input_xlsx_path, sheet_name=\"Transaksi\")\n",
    "\n",
    "    # Pastikan dua kolom penting ada dalam data\n",
    "    if not {\"Kode Transaksi\", \"Nama Produk\"}.issubset(df.columns):\n",
    "        raise ValueError(\"Kolom 'Kode Transaksi' dan 'Nama Produk' wajib ada di sheet 'Transaksi'.\")\n",
    "\n",
    "    # Kita hanya ambil dua kolom yang diperlukan, lalu hapus baris kosong\n",
    "    df = df[[\"Kode Transaksi\", \"Nama Produk\"]].dropna()\n",
    "\n",
    "    # Bersihkan data dari spasi dan pastikan formatnya string\n",
    "    df[\"Kode Transaksi\"] = df[\"Kode Transaksi\"].astype(str).str.strip()\n",
    "    df[\"Nama Produk\"] = df[\"Nama Produk\"].astype(str).str.strip()\n",
    "\n",
    "    # Jika ternyata data kosong setelah dibersihkan, buat file kosong berheader\n",
    "    if df.empty:\n",
    "        pd.DataFrame(columns=[\"Packaging Set ID\", \"Products\", \"Maximum Lift\", \"Maximum Confidence\"])\\\n",
    "            .to_excel(output_xlsx_path, index=False)\n",
    "        return\n",
    "\n",
    "    # =====================================================================\n",
    "    # 2. Mengubah data transaksi menjadi format basket (matrix transaksi × produk)\n",
    "    # =====================================================================\n",
    "    # Setiap baris transaksi akan dikonversi ke bentuk \"one-hot encoded\"\n",
    "    # di mana setiap kolom mewakili produk tertentu.\n",
    "    # Nilai 1 berarti produk tersebut dibeli dalam transaksi itu, 0 berarti tidak.\n",
    "    # =====================================================================\n",
    "    basket = (\n",
    "        df.groupby([\"Kode Transaksi\", \"Nama Produk\"])[\"Nama Produk\"]\n",
    "        .count().unstack(fill_value=0)\n",
    "    )\n",
    "\n",
    "    # Konversi ke tipe boolean (True/False) agar sesuai dengan format yang diharapkan oleh mlxtend\n",
    "    basket = (basket > 0).astype(int)\n",
    "\n",
    "    # Jika matrix basket kosong, buat file kosong saja agar tidak error\n",
    "    if basket.empty:\n",
    "        pd.DataFrame(columns=[\"Packaging Set ID\", \"Products\", \"Maximum Lift\", \"Maximum Confidence\"])\\\n",
    "            .to_excel(output_xlsx_path, index=False)\n",
    "        return\n",
    "\n",
    "    # =====================================================================\n",
    "    # 3. Menjalankan algoritma Apriori\n",
    "    # =====================================================================\n",
    "    # Apriori digunakan untuk mencari kombinasi produk yang sering muncul bersama.\n",
    "    # Parameter:\n",
    "    #   - min_support = 0.05 → artinya kombinasi harus muncul di minimal 5% transaksi.\n",
    "    #   - use_colnames=True agar hasilnya tetap memakai nama produk asli, bukan indeks kolom.\n",
    "    # =====================================================================\n",
    "    frequent_itemsets = apriori(basket, min_support=0.05, use_colnames=True)\n",
    "\n",
    "    # Jika tidak ada kombinasi yang memenuhi syarat support minimal, hasil kosong\n",
    "    if frequent_itemsets.empty:\n",
    "        pd.DataFrame(columns=[\"Packaging Set ID\", \"Products\", \"Maximum Lift\", \"Maximum Confidence\"])\\\n",
    "            .to_excel(output_xlsx_path, index=False)\n",
    "        return\n",
    "\n",
    "    # =====================================================================\n",
    "    # 4. Membentuk aturan asosiasi (Association Rules)\n",
    "    # =====================================================================\n",
    "    # Setelah kombinasi produk ditemukan, kita ingin tahu hubungan antarproduk.\n",
    "    # Fungsi 'association_rules' menghasilkan metrik seperti lift dan confidence.\n",
    "    # Kita gunakan metrik 'confidence' dengan ambang minimal 0.4 (40%) seperti di soal.\n",
    "    # =====================================================================\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.4)\n",
    "\n",
    "    # Jika tidak ada aturan yang memenuhi, buat file kosong saja\n",
    "    if rules.empty:\n",
    "        pd.DataFrame(columns=[\"Packaging Set ID\", \"Products\", \"Maximum Lift\", \"Maximum Confidence\"])\\\n",
    "            .to_excel(output_xlsx_path, index=False)\n",
    "        return\n",
    "\n",
    "    # =====================================================================\n",
    "    # 5. Menyatukan antecedents dan consequents menjadi satu set produk\n",
    "    # =====================================================================\n",
    "    # Setiap aturan memiliki dua sisi:\n",
    "    #   - antecedents: produk awal (misalnya Product A)\n",
    "    #   - consequents: produk yang cenderung dibeli bersamaan (misalnya Product B)\n",
    "    # Kita gabungkan keduanya agar merepresentasikan satu paket produk lengkap.\n",
    "    # =====================================================================\n",
    "    def union_sets(row):\n",
    "        return row[\"antecedents\"].union(row[\"consequents\"])\n",
    "\n",
    "    rules[\"product_set\"] = rules.apply(union_sets, axis=1)\n",
    "\n",
    "    # =====================================================================\n",
    "    # 6. Menyaring kombinasi produk tunggal (karena paket minimal 2 produk)\n",
    "    # =====================================================================\n",
    "    rules = rules[rules[\"product_set\"].apply(len) >= 2]\n",
    "\n",
    "    # Jika hasil kosong, buat file kosong\n",
    "    if rules.empty:\n",
    "        pd.DataFrame(columns=[\"Packaging Set ID\", \"Products\", \"Maximum Lift\", \"Maximum Confidence\"])\\\n",
    "            .to_excel(output_xlsx_path, index=False)\n",
    "        return\n",
    "\n",
    "    # =====================================================================\n",
    "    # 7. Mengurutkan nama produk dalam setiap kombinasi dan membuat string gabungan\n",
    "    # =====================================================================\n",
    "    # Setiap kombinasi produk diurutkan berdasarkan abjad untuk menghindari duplikasi palsu.\n",
    "    # Contoh: {Product 20, Product 4, Product 25} akan diubah menjadi \"Product 4;Product 20;Product 25\".\n",
    "    # =====================================================================\n",
    "    rules[\"Products\"] = rules[\"product_set\"].apply(lambda s: \";\".join(sorted(s)))\n",
    "\n",
    "    # =====================================================================\n",
    "    # 8. Menggabungkan kombinasi duplikat\n",
    "    # =====================================================================\n",
    "    # Bisa jadi ada beberapa aturan berbeda yang menghasilkan kombinasi produk yang sama.\n",
    "    # Maka, kita gabungkan berdasarkan kolom 'Products' dan ambil nilai lift & confidence tertinggi.\n",
    "    # =====================================================================\n",
    "    agg = (\n",
    "        rules.groupby(\"Products\")\n",
    "        .agg(Maximum_Lift=(\"lift\", \"max\"), Maximum_Confidence=(\"confidence\", \"max\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # =====================================================================\n",
    "    # 9. Mengurutkan hasil akhir berdasarkan lift tertinggi, lalu confidence tertinggi\n",
    "    # =====================================================================\n",
    "    # Kombinasi produk dengan lift lebih besar berarti asosiasinya lebih kuat,\n",
    "    # sehingga ditampilkan paling atas dalam file hasil.\n",
    "    # =====================================================================\n",
    "    agg = agg.sort_values(by=[\"Maximum_Lift\", \"Maximum_Confidence\"], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "    # =====================================================================\n",
    "    # 10. Menambahkan kolom Packaging Set ID\n",
    "    # =====================================================================\n",
    "    # Kolom ini adalah nomor urut (1, 2, 3, ...) untuk memudahkan pembaca non-teknis.\n",
    "    # =====================================================================\n",
    "    agg.insert(0, \"Packaging Set ID\", range(1, len(agg) + 1))\n",
    "\n",
    "    # =====================================================================\n",
    "    # 11. Menyimpan hasil akhir ke file Excel\n",
    "    # =====================================================================\n",
    "    # File akhir bernama \"product_packaging.xlsx\" seperti yang diminta soal.\n",
    "    # =====================================================================\n",
    "    agg.to_excel(output_xlsx_path, index=False)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# Pemanggilan fungsi utama (contoh penggunaan)\n",
    "# =====================================================================\n",
    "# Saat file dijalankan langsung (bukan diimpor), fungsi ini otomatis dijalankan.\n",
    "# Dalam sistem penilaian, fungsi ini juga akan dipanggil dengan cara yang sama:\n",
    "# run_analysis(\"transaksi_dqmart.xlsx\", \"product_packaging.xlsx\")\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_analysis(\"transaksi_dqmart.xlsx\", \"product_packaging.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
